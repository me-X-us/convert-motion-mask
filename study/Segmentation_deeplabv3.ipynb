{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation_deeplabv3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqLkn7RtN8o5",
        "outputId": "b1717256-1003-4243-9a02-e824c7a75f0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as T\n",
        "import cv2\n",
        "import numpy as np\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "# colab 환경을 위한 패키지\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n",
            "0.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgxv-irIPwEC",
        "outputId": "3ee5ee58-719a-4493-a833-bf56e277ba17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# GPU 사용 여부\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APGgQZZQdQZR"
      },
      "source": [
        "COLORS = np.array([\n",
        "    (255, 255, 255), # background -> 하얀색\n",
        "    (192, 128, 128), # person\n",
        " \n",
        "])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut_cWHS2Q395"
      },
      "source": [
        "model = models.segmentation.deeplabv3_resnet101(pretrained=True).eval()\n",
        "if device == 'cuda':\n",
        "    model = model.to(device)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HVs4amzTtwD"
      },
      "source": [
        "def preprocess(img):\n",
        "    trf = T.Compose([\n",
        "                    T.ToTensor(),\n",
        "                    # T.CenterCrop(IMG_SIZE),\n",
        "                    T.Normalize(\n",
        "                        mean=[0.485, 0.456, 0.406],\n",
        "                        std = [0.229, 0.224, 0.225]\n",
        "                    ),\n",
        "    ])\n",
        "    input_img = trf(img).unsqueeze(0)\n",
        "    if device == 'cuda':\n",
        "        input_img = input_img.to(device)\n",
        "    return input_img"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMUfAGlpdHvC"
      },
      "source": [
        "def seg_map(img, n_classes=21):\n",
        "    color_idx = 0\n",
        "    rgb = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "    for i in (0,15): # 사람과 배경의 경우만 색칠\n",
        "        idx = img == i\n",
        "        rgb[idx] = COLORS[color_idx]\n",
        "        color_idx = color_idx + 1\n",
        "\n",
        "    return rgb"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3o8mFLPREjc",
        "outputId": "6f48679d-187b-47fc-cce2-c34951684479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "IMG_SIZE = 480\n",
        "count = 0\n",
        "cap = cv2.VideoCapture('./testvid.mp4')\n",
        "nof_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "ret, img = cap.read()\n",
        "img.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1080, 1920, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-fkIvZ7TGBf"
      },
      "source": [
        "# video writer 구성\n",
        "video_format = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out_video = cv2.VideoWriter('./output.mp4',video_format,cap.get(cv2.CAP_PROP_FPS),(IMG_SIZE,int(img.shape[0] * IMG_SIZE / img.shape[1])))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FQyMYJvUHfW"
      },
      "source": [
        "while cap.isOpened():\n",
        "    ret, img = cap.read()\n",
        "    \n",
        "    # 이미지 사이즈 조정\n",
        "    if not ret:\n",
        "        break;\n",
        "    print(ret)\n",
        "    img = cv2.resize(img,(IMG_SIZE,int(img.shape[0] * IMG_SIZE / img.shape[1])))\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    input_tensor = preprocess(img)\n",
        "    out = model(input_tensor)['out'][0]\n",
        "    # print(out.shape) (21,270,480)\n",
        "    out = out.argmax(0).detach().cpu().numpy()\n",
        "    # print(np.unique(out))   # 0  15 배경과 사람만 detect\n",
        "    out = seg_map(out)\n",
        "    # cv2_imshow(out)\n",
        "    out = cv2.cvtColor(out, cv2.COLOR_RGB2BGR)\n",
        "    # print(out.shape)  (270, 480, 3)\n",
        "    out_video.write(out)\n",
        "    # print(seg_map(out))\n",
        "    print(\"Frame : \", nof_frame, count)\n",
        "    count = count + 1\n",
        "cap.release()\n",
        "out_video.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}